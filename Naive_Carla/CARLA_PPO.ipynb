{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 23:53:52.314667: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-30 23:53:52.605123: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-30 23:53:53.676536: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/kololhe/.local/lib/python3.8/site-packages/cv2/../../lib64:/opt/ros/noetic/lib\n",
      "2023-04-30 23:53:53.676809: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/kololhe/.local/lib/python3.8/site-packages/cv2/../../lib64:/opt/ros/noetic/lib\n",
      "2023-04-30 23:53:53.676817: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import gym as gym\n",
    "from gym import spaces\n",
    "import carla\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo.policies import MlpPolicy\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "import csv\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 25\n",
    "CSV_FILE = '/home/kololhe/stuff/waypoint_with_xy.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_waypoints(file_path):\n",
    "    waypoints = []\n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        for row in csvreader:\n",
    "            v, yaw_c, yaw_n, r, x, y = map(float, row)\n",
    "            waypoints.append((v, yaw_c, yaw_n, r, x, y))\n",
    "            \n",
    "    return waypoints  \n",
    "\n",
    "\n",
    "def setupCarla():\n",
    "\n",
    "    # Connect to CARLA server\n",
    "    client = carla.Client('localhost', 2000)\n",
    "    client.set_timeout(10.0)\n",
    "\n",
    "    return client.get_world()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarlaInstance(gym.Env):\n",
    "    metadata = {}\n",
    "\n",
    "    def __init__(self, world, waypoints):\n",
    "        #super(CarlaInstance, self).__init__()\n",
    "        try:\n",
    "            self.reached_waypoint_list = []\n",
    "            self.waypoints = waypoints\n",
    "            self.current_waypoint_index = 0\n",
    "            \n",
    "\n",
    "            self.blueprint_library = world.get_blueprint_library()\n",
    "            world.set_weather(carla.WeatherParameters.ClearNoon)\n",
    "\n",
    "\n",
    "            # Spawn vehicle\n",
    "            vehicle_bp = random.choice(self.blueprint_library.filter('wrangler_rubicon'))\n",
    "            spawn_point = carla.Transform(carla.Location(x=-23.6,y=137.5,z=1),carla.Rotation(yaw=0))\n",
    "            self.vehicle = world.spawn_actor(vehicle_bp, spawn_point)\n",
    "            #self.vehicle.set_simulate_physics(True)\n",
    "            self.vehicle.apply_control(carla.VehicleControl(throttle=0.0, brake=0.0, steer=0.0))\n",
    "            sleep(2.0)\n",
    "\n",
    "            # Attach Lane Invasion Sensor to car\n",
    "            sensor_bp = world.get_blueprint_library().find('sensor.other.lane_invasion')\n",
    "            sensor_transform = carla.Transform(carla.Location(x=2.5, z=0.7))\n",
    "            self.lane_invasion_sensor = world.spawn_actor(sensor_bp, sensor_transform, attach_to=self.vehicle)\n",
    "            self.lane_invasion_sensor.listen(lambda event: self.on_lane_invasion(event))\n",
    "\n",
    "            self.collision_sensor = world.spawn_actor(world.get_blueprint_library().find('sensor.other.collision'), sensor_transform, attach_to=self.vehicle)\n",
    "            self.collision_sensor.listen(lambda event: self.on_lane_invasion(event))\n",
    "\n",
    "            self.action_space = spaces.MultiDiscrete([11, 21, 11])\n",
    "            self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(40, ), dtype=np.float64)\n",
    "            self.problem = bool\n",
    "            self.reset()\n",
    "\n",
    "        except RuntimeError or KeyboardInterrupt:\n",
    "            print(\"entered init exception\")\n",
    "            for actor in world.get_actors():\n",
    "                actor.destroy()\n",
    "            pass\n",
    "\n",
    "    def on_lane_invasion(self, event):\n",
    "        self.problem = True \n",
    "        self.reset()\n",
    "    \n",
    "    def step(self, action):\n",
    "\n",
    "        throttle = action[0]/10.0\n",
    "        \n",
    "        self.reached_waypoint_list.append(self.current_waypoint_index)\n",
    "\n",
    "        if action[1] == 0:\n",
    "            steer = 0.0\n",
    "        elif action[1] <= 10:\n",
    "            steer = -action[1]/10.0\n",
    "        elif action[1]>10:\n",
    "            steer = (action[1]-10.0)/10.0\n",
    "\n",
    "        brake = action[2]/10.0\n",
    "\n",
    "        if self.current_waypoint_index <10:\n",
    "            throttle = 1.0\n",
    "            brake = 0.0\n",
    "            steer = 0.0\n",
    "\n",
    "                        \n",
    "        elif self.current_waypoint_index == 10:\n",
    "            self.moving = True\n",
    "\n",
    "        control = carla.VehicleControl(throttle=float(throttle), brake=float(brake), steer=float(steer)) #, steer=steer)\n",
    "        self.vehicle.apply_control(control)\n",
    "\n",
    "\n",
    "\n",
    "        obs = self.get_observation()\n",
    "\n",
    "        \n",
    "        \n",
    "        # next_waypoint = self.waypoints[self.current_waypoint_index]\n",
    "        # next_waypoint_location = carla.Location(x=next_waypoint[0], y=next_waypoint[1])\n",
    "        # current_location = self.vehicle.get_location()\n",
    "        # distance = current_location.distance(next_waypoint_location)\n",
    "\n",
    "        reward = self.get_reward(obs)\n",
    "\n",
    "        done = self.is_done(obs[3])\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "                                              \n",
    "\n",
    "        #reward = self.get_reward(distance, control)\n",
    "        #done = False\n",
    "\n",
    "        info = {}\n",
    "\n",
    "        sleep(0.1)\n",
    "\n",
    "        return obs, reward, done, info\n",
    "    \n",
    "    \n",
    "    def get_observation(self):\n",
    "        state = []\n",
    "        curr_yaw = self.vehicle.get_transform().rotation.yaw        \n",
    "        \n",
    "        for i in range(10):\n",
    "            if self.current_waypoint_index + i < len(self.waypoints):\n",
    "                waypoint = self.waypoints[self.current_waypoint_index + i]\n",
    "                curr_vel = self.vehicle.get_velocity()\n",
    "                curr_loc = self.vehicle.get_location()\n",
    "                vx = curr_vel.x\n",
    "                vy = curr_vel.y\n",
    "                v = ((vx)**2+(vy)**2)**0.5\n",
    "                distance = curr_loc.distance(carla.Location(x=waypoint[4],y=waypoint[5]))\n",
    "                if distance >100:\n",
    "                    distance =0\n",
    "                state.extend([v, curr_yaw - waypoint[1], curr_yaw - waypoint[2], distance ])\n",
    "                self.reached_waypoint_list.append(self.current_waypoint_index)\n",
    "            else:\n",
    "                state.extend([0, 0, 0, 0])\n",
    "        return np.array(state)\n",
    "    \n",
    "    def get_reward(self, state):\n",
    "        reward = -(np.linalg.norm(state[0] - self.waypoints[self.current_waypoint_index][0]) - (np.linalg.norm (state[1])) - (np.linalg.norm ( state[2])) - (np.linalg.norm (state[3])) + self.current_waypoint_index)\n",
    "        return reward\n",
    "    \n",
    "    def close(self):\n",
    "        self.vehicle.destroy()\n",
    "        self.lane_invasion_sensor.destroy()\n",
    "        self.collision_sensor.destroy()    \n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        vel = carla.Vector3D()\n",
    "        vel.x = 0\n",
    "        vel.y = 0\n",
    "        vel.z = 0\n",
    "        self.vehicle.set_target_velocity(vel)\n",
    "        transform = carla.Transform(carla.Location(x=-23.6,y=137.5),carla.Rotation(yaw=0))\n",
    "        self.vehicle.set_transform(transform)\n",
    "        self.current_waypoint_index = 0        \n",
    "        self.moving = False\n",
    "        #info = {}\n",
    "\n",
    "        return self.get_observation()\n",
    "    \n",
    "    def render(self):\n",
    "        pass\n",
    "\n",
    "    def is_done(self, state):\n",
    "\n",
    "\n",
    "        distance = np.abs(state)/100.0\n",
    "\n",
    "        if distance < 0.4:  # If the vehicle is close to the next waypoint                                                                                        \n",
    "            self.current_waypoint_index += 1  \n",
    "\n",
    "        if len(self.reached_waypoint_list) >=21:\n",
    "            if self.reached_waypoint_list[len(self.reached_waypoint_list)-1] == self.reached_waypoint_list[len(self.reached_waypoint_list) - 20] and self.moving:\n",
    "                return  True\n",
    "        if self.current_waypoint_index >= len(self.waypoints):\n",
    "            return True\n",
    "    \n",
    "        \n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to /home/kololhe/stuff/PPO_training_curve/PPO_10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1715569d7d64eba9559cbbc7d997fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 75.6     |\n",
      "|    ep_rew_mean     | -151     |\n",
      "| time/              |          |\n",
      "|    fps             | 9        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 213      |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Create a vectorized environment with SubprocVecEnv\n",
    "num_envs=1\n",
    "env = CarlaInstance(world = setupCarla(), waypoints = read_waypoints(CSV_FILE))\n",
    "\n",
    "check_env(env)\n",
    "\n",
    "# Instantiate the PPO agent\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1, gamma=0.99, tensorboard_log=\"/home/kololhe/stuff/PPO_training_curve/\", learning_rate=0.00099)\n",
    "\n",
    "# Train the agent\n",
    "model.learn(total_timesteps=1000000, progress_bar=True, reset_num_timesteps=50000)\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"carla_ppo\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
