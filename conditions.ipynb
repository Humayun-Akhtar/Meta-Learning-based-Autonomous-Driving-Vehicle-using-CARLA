{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import carla\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import learn2learn as l2l\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from collections import deque\n",
    "import copy\n",
    "import time\n",
    "import math\n",
    "class Vector:\n",
    "    def __init__(self, x, y, z):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "threshold = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CarlaEnv(gym.Env):\n",
    "    def __init__(self, vehicle, waypoints):\n",
    "        super(CarlaEnv, self).__init__()\n",
    "        self.vehicle = vehicle\n",
    "        self.waypoints = waypoints\n",
    "        self.current_waypoint_index = 0\n",
    "\n",
    "        self.action_space = spaces.Discrete(4)  # [throttle, brake, steer_left, steer_right]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(5,), dtype=np.float32)\n",
    "\n",
    "        self.lane_invasion = False\n",
    "#         print('CarlaEnv made')\n",
    "#         self.lane_invasion_sensor = self._spawn_lane_invasion_sensor()\n",
    "        \n",
    "#     def _spawn_lane_invasion_sensor(self):\n",
    "#         sensor_bp = self.world.get_blueprint_library().find('sensor.other.lane_invasion')\n",
    "#         sensor_transform = carla.Transform(carla.Location(x=2.5, z=0.7))\n",
    "#         sensor = self.world.spawn_actor(sensor_bp, sensor_transform, attach_to=self.vehicle)\n",
    "#         sensor.listen(lambda event: self._on_lane_invasion(event))\n",
    "#         return sensor\n",
    "\n",
    "    def _on_lane_invasion(self, event):\n",
    "#         print(\"lane invasion detected\")\n",
    "        self.lane_invasion = True    \n",
    "\n",
    "    def reset(self):\n",
    "        vel = carla.Vector3D()\n",
    "        vel.x = 0\n",
    "        vel.y = 0\n",
    "        vel.z = 0\n",
    "        self.vehicle.set_target_velocity(vel)\n",
    "        x, y, yaw = self.waypoints[0]\n",
    "        transform = carla.Transform(carla.Location(x, y), carla.Rotation(yaw=yaw))\n",
    "        self.vehicle.set_transform(transform)\n",
    "#         print(\"reset done\")\n",
    "        return self._get_observation()\n",
    "\n",
    "    def step(self, action):\n",
    "        throttle = 0\n",
    "        brake = 0\n",
    "        steer = 0\n",
    "\n",
    "        if action == 0:\n",
    "            throttle = 1.0\n",
    "        elif action == 1:\n",
    "            brake = 1.0\n",
    "        elif action == 2:\n",
    "            steer = -1.0\n",
    "        \n",
    "        elif action == 3:\n",
    "            steer = 1.0\n",
    "            \n",
    "\n",
    "        control = carla.VehicleControl(throttle=throttle, brake=brake, steer=steer)\n",
    "        self.vehicle.apply_control(control)\n",
    "\n",
    "        next_waypoint = self.waypoints[self.current_waypoint_index]\n",
    "        next_waypoint_location = carla.Location(x=next_waypoint[0], y=next_waypoint[1])\n",
    "        current_location = self.vehicle.get_location()\n",
    "        distance = current_location.distance(next_waypoint_location)\n",
    "\n",
    "        if distance < threshold:\n",
    "            self.current_waypoint_index += 1\n",
    "            if self.current_waypoint_index >= len(self.waypoints):\n",
    "                self.current_waypoint_index = 0\n",
    "\n",
    "        reward = self._get_reward(distance, control)\n",
    "\n",
    "        done = False\n",
    "        if self.current_waypoint_index == len(self.waypoints) - 1:\n",
    "            done = True\n",
    "#         print (f'step taken: Throttle: {throttle} and steer: {steer}')\n",
    "        return self._get_observation(), reward, done, {}\n",
    "\n",
    "    def _get_observation(self):\n",
    "        location = self.vehicle.get_location()\n",
    "        orientation = self.vehicle.get_transform().rotation.yaw\n",
    "        speed = self.vehicle.get_velocity()\n",
    "        speed = np.sqrt(speed.x**2 + speed.y**2 + speed.z**2)\n",
    "        next_waypoint = self.waypoints[self.current_waypoint_index]\n",
    "        next_waypoint_location = carla.Location(x=next_waypoint[0], y=next_waypoint[1])\n",
    "        distance = location.distance(next_waypoint_location)\n",
    "#         print('observation taken')\n",
    "        return np.array([location.x, location.y, orientation, speed, distance])\n",
    "\n",
    "\n",
    "    def _get_reward(self, distance, control):\n",
    "        reward = 0\n",
    "        if control.throttle > 0:\n",
    "            reward += 0\n",
    "        if distance < threshold:\n",
    "            reward += 10    \n",
    "        # Apply a large negative reward for lane invasion\n",
    "        if self.lane_invasion:\n",
    "            reward -= 1000  # Adjust the value as needed\n",
    "            self.lane_invasion = True    \n",
    "#         print('reward calculated')    \n",
    "        return reward\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class trainer(CarlaEnv):\n",
    "    def __init__(self, episodes, steps, sample_size, learner, meta_optim):\n",
    "        self.episodes = episodes\n",
    "        self.steps = steps\n",
    "        self.sample_size = sample_size\n",
    "        self.learner = learner\n",
    "        self.meta_optim = meta_optim\n",
    "        \n",
    "\n",
    "    def setup(self, weather):\n",
    "        \n",
    "        try:\n",
    "            state_size = 5\n",
    "            action_size = 4\n",
    "            agent = PolicyNetwork(state_size, action_size)\n",
    "            #target_agent = copy.deepcopy(agent)\n",
    "            #optimizer = optim.Adam(agent.parameters(), lr=LEARNING_RATE)\n",
    "            memory = deque(maxlen=MEMORY_SIZE)\n",
    "\n",
    "\n",
    "            # Read waypoints from CSV\n",
    "            waypoints = read_waypoints(CSV_FILE)\n",
    "\n",
    "            # Connect to CARLA server\n",
    "            client = carla.Client('localhost', 2000)\n",
    "            client.set_timeout(10.0)\n",
    "\n",
    "            # Load CARLA world\n",
    "            world = client.get_world()\n",
    "            \n",
    "            current_weather = weather\n",
    "            print(current_weather)\n",
    "            if current_weather == \"HardRainNoon\":\n",
    "                world.set_weather(carla.WeatherParameters.HardRainNoon)\n",
    "\n",
    "            \n",
    "            blueprint_library = world.get_blueprint_library()\n",
    "\n",
    "            # Spawn vehicle\n",
    "            vehicle_bp = random.choice(blueprint_library.filter('wrangler_rubicon'))\n",
    "            spawn_point = carla.Transform(carla.Location(x=-23.6,y=137.5,z=1),carla.Rotation(yaw=0))\n",
    "            self.vehicle = world.spawn_actor(vehicle_bp, spawn_point)\n",
    "\n",
    "            sensor_bp = world.get_blueprint_library().find('sensor.other.lane_invasion')\n",
    "            sensor_transform = carla.Transform(carla.Location(x=2.5, z=0.7))\n",
    "            self.sensor = world.spawn_actor(sensor_bp, sensor_transform, attach_to=self.vehicle)\n",
    "            self.sensor.listen(lambda event: self.env._on_lane_invasion(event))\n",
    "\n",
    "            # Create CARLA environment\n",
    "            self.env = CarlaEnv(self.vehicle, waypoints)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "\n",
    "    def generate_traj(self):\n",
    "\n",
    "        self.states_buffer = np.empty((self.sample_size, self.steps))\n",
    "        action_buffer = np.empty((self.sample_size, self.steps))\n",
    "        rewards_buffer = np.empty((self.sample_size, self.steps))\n",
    "        next_states_buffer = np.empty((self.sample_size, self.steps))\n",
    "    \n",
    "        for episode in range(self.sample_size):\n",
    "            state = self.env.reset()\n",
    "            self.env.current_waypoint_index = 0\n",
    "            self.env.lane_invasion = False\n",
    "            episode_reward = 0\n",
    "\n",
    "            states = []\n",
    "            actions = []\n",
    "            rewards = []\n",
    "            next_states = []\n",
    "\n",
    "            for step in range(self.steps):\n",
    "                \n",
    "                #states = []\n",
    "                #actions = []\n",
    "                #rewards = []\n",
    "                #next_states = []\n",
    "\n",
    "                # Observe\n",
    "                state = self.env._get_observation()\n",
    "                next_waypoint = self.env.waypoints[self.env.current_waypoint_index]\n",
    "                action = waypoint_based_action(self.vehicle, next_waypoint)\n",
    "\n",
    "                \n",
    "                next_state, reward, done, _ = self.env.step(action.item())\n",
    "                next_state = torch.tensor(next_state, dtype=torch.float32).unsqueeze(0)\n",
    "                state = next_state\n",
    "                episode_reward += reward\n",
    "\n",
    "                states.append(state)\n",
    "                actions.append(action)\n",
    "                rewards.append(reward)\n",
    "                next_states.append(next_state)\n",
    "\n",
    "            self.states_buffer.append(states)\n",
    "            action_buffer = np.stack((action_buffer, actions))\n",
    "            rewards_buffer = np.vstack((rewards_buffer, rewards))\n",
    "            next_states_buffer = np.vstack((next_states_buffer, next_state))\n",
    "\n",
    "            \n",
    "            #print(episode)\n",
    "        print(actions)\n",
    "\n",
    "    def destroy(self):\n",
    "        # Destroy the vehicle in CARLA\n",
    "        self.sensor.destroy()                      \n",
    "        self.vehicle.destroy()\n",
    "        print(\"All Cleared\")\n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "    def meta_train(self):\n",
    "\n",
    "        # Compute loss\n",
    "        loss = F.cross_entropy(self.learner(self.states_buffer), action)\n",
    "\n",
    "        # Compute gradients and update model\n",
    "        self.learner.adapt(loss.item())\n",
    "\n",
    "        # Meta update\n",
    "        self.meta_optim.zero_grad()\n",
    "        mean_task_loss = torch.mean(torch.tensor(task_losses))\n",
    "        mean_task_loss.backward()\n",
    "        self.meta_optim.step()\n",
    "            \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Version mismatch detected: You are trying to connect to a simulator that might be incompatible with this API \n",
      "WARNING: Client API version     = 0.9.14 \n",
      "WARNING: Simulator API version  = 0.9.14-4-gf14acb257-dirty \n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "p_low = 0\n",
    "p_mid = 50\n",
    "p_high = 100\n",
    "\n",
    "pd_low = 50\n",
    "pd_high = 100\n",
    "\n",
    "tf_low = 0.5\n",
    "tf_mid = 1.5\n",
    "tf_high = 2.5\n",
    "\n",
    "conditions = [[p_low, pd_low, tf_high],\n",
    "            [p_low, pd_low, tf_mid],\n",
    "            [p_low, pd_high, tf_low],\n",
    "            [p_mid, pd_low, tf_low],\n",
    "            [p_mid, pd_high, tf_low],\n",
    "            [p_mid, pd_low, tf_mid],\n",
    "            [p_high, pd_low, tf_high],\n",
    "            [p_high, pd_high, tf_low],\n",
    "            [p_low, pd_high, tf_mid],\n",
    "            [p_high, pd_low, tf_mid]]\n",
    "\n",
    "n_tasks = len(conditions)\n",
    "\n",
    "client = carla.Client('localhost', 2000)\n",
    "client.set_timeout(10.0)\n",
    "\n",
    "# Load CARLA world\n",
    "world = client.get_world()\n",
    "\n",
    "blueprint_library = world.get_blueprint_library()\n",
    "# Spawn vehicle\n",
    "vehicle_bp = random.choice(blueprint_library.filter('wrangler_rubicon'))\n",
    "spawn_point = carla.Transform(carla.Location(x=-23.6,y=137.5,z=1),carla.Rotation(yaw=0))\n",
    "vehicle = world.spawn_actor(vehicle_bp, spawn_point)\n",
    "\n",
    "for condition in conditions:\n",
    "    precipitation = condition[0]\n",
    "    precipitation_deposits = condition[1]\n",
    "    tire_friction = condition[2]\n",
    "    weather = carla.WeatherParameters( precipitation = precipitation,\n",
    "                                        precipitation_deposits = precipitation_deposits)\n",
    "    world.set_weather(weather)\n",
    "\n",
    "    tire_condition = carla.WheelPhysicsControl(tire_friction = tire_friction)\n",
    "\n",
    "    front_left_wheel  = carla.WheelPhysicsControl(tire_friction = tire_friction)\n",
    "    front_right_wheel = carla.WheelPhysicsControl(tire_friction = tire_friction)\n",
    "    rear_left_wheel   = carla.WheelPhysicsControl(tire_friction = tire_friction)\n",
    "    rear_right_wheel  = carla.WheelPhysicsControl(tire_friction = tire_friction)\n",
    "\n",
    "    wheels = [front_left_wheel, front_right_wheel, rear_left_wheel, rear_right_wheel]\n",
    "    blueprint_library = world.get_blueprint_library()\n",
    "    physics_control = vehicle.get_physics_control()\n",
    "    physics_control.wheels = wheels\n",
    "    vehicle.apply_physics_control(physics_control)\n",
    "    time.sleep(10)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    #sensor_bp = world.get_blueprint_library().find('sensor.other.lane_invasion')\n",
    "    #sensor_transform = carla.Transform(carla.Location(x=2.5, z=0.7))\n",
    "    #sensor = world.spawn_actor(sensor_bp, sensor_transform, attach_to=vehicle)\n",
    "    #sensor.listen(lambda event: env._on_lane_invasion(event))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create CARLA environment\n",
    "#env = CarlaEnv(self.vehicle, waypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
