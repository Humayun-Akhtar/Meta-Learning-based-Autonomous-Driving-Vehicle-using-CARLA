{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09fd2570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import carla\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Normal\n",
    "import learn2learn as l2l\n",
    "import csv\n",
    "import time\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "\n",
    "        self.l1 = nn.Linear(state_dim, 64)\n",
    "        self.l2 = nn.Linear(64, 64)\n",
    "        self.l3 = nn.Linear(64, action_dim)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.l1(state))\n",
    "        x = F.relu(self.l2(x))\n",
    "        #action_logits = self.l3(x)\n",
    "        actions = self.l3(x)\n",
    "        #ction_probs = F.softmax(action_logits, dim=1)\n",
    "\n",
    "        return actions\n",
    "\n",
    "\n",
    "class CarlaEnvironment:\n",
    "    def __init__(self, world, vehicle_blueprint, waypoints):\n",
    "        self.world = world\n",
    "        self.vehicle_blueprint = vehicle_blueprint\n",
    "        self.waypoints = waypoints\n",
    "        self.actorlist = []\n",
    "        self.vehicle = self.world.spawn_actor(self.vehicle_blueprint, carla.Transform(carla.Location(x=-23.6,y=137.5,z=1),carla.Rotation(yaw=0)))\n",
    "        \n",
    "    def reset(self):\n",
    "        self.vehicle.destroy()\n",
    "        self.vehicle = self.world.spawn_actor(self.vehicle_blueprint, carla.Transform(carla.Location(x=-23.6,y=137.5,z=1),carla.Rotation(yaw=0)))  \n",
    "        self.current_waypoint = 0\n",
    "        return self.get_state()\n",
    "\n",
    "    def step(self, action):\n",
    "        action = action.detach().numpy()\n",
    "        #print(action)\n",
    "        # Apply actions: Throttle, Steering, Brake\n",
    "        self.vehicle.apply_control(carla.VehicleControl(throttle = float(action[0]) , steer = float(action[1]) , brake = float(action[2])))\n",
    "       \n",
    "        #self.actorlist.append(self.vehicle)\n",
    "\n",
    "        # Get next state\n",
    "        next_state = self.get_state()\n",
    "\n",
    "        # Calculate reward\n",
    "        reward = self.calculate_reward(next_state) \n",
    "\n",
    "        # Check if the episode is done\n",
    "        done = self.is_done(next_state)\n",
    "\n",
    "        return next_state, reward, done\n",
    "\n",
    "#     def get_state(self):\n",
    "#         curr_vel = self.vehicle.get_velocity()\n",
    "#         curr_yaw = self.vehicle.get_transform().rotation.yaw\n",
    "#         waypoint = self.waypoints[self.current_waypoint]\n",
    "#         return np.array([curr_vel, curr_yaw - waypoint[1], curr_yaw - waypoint[2], waypoint[3]])\n",
    "    \n",
    "    def get_state(self):\n",
    "        state = []\n",
    "        curr_yaw = self.vehicle.get_transform().rotation.yaw\n",
    "        \n",
    "        \n",
    "        for i in range(10):\n",
    "            if self.current_waypoint + i < len(self.waypoints):\n",
    "                waypoint = self.waypoints[self.current_waypoint + i]\n",
    "                curr_vel = self.vehicle.get_velocity()\n",
    "                curr_loc = self.vehicle.get_location()\n",
    "                vx = curr_vel.x\n",
    "                vy = curr_vel.y\n",
    "                v = ((vx)**2+(vy)**2)**0.5\n",
    "                distance = curr_loc.distance(carla.Location(x=waypoint[4],y=waypoint[5]))\n",
    "                state.extend([v, curr_yaw - waypoint[1], curr_yaw - waypoint[2], distance ])\n",
    "            else:\n",
    "                state.extend([0, 0, 0, 0])\n",
    "        return np.array(state)\n",
    "\n",
    "    def generate_waypoints(self):\n",
    "        # Implement waypoint generation logic\n",
    "        pass\n",
    "\n",
    "    def calculate_reward(self, state):\n",
    "        reward = -(np.linalg.norm(state[0] - self.waypoints[self.current_waypoint][0]) - (np.linalg.norm (state[1])) - (np.linalg.norm ( state[2])) - (np.linalg.norm (state[3])) + self.current_waypoint)\n",
    "        return reward\n",
    "\n",
    "    def is_done(self, state):\n",
    "        if np.abs(state[3]) < 0.20:  # If the vehicle is close to the next waypoint\n",
    "            self.current_waypoint += 1\n",
    "\n",
    "        if self.current_waypoint >= len(self.waypoints):\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def set_weather(self, weather):\n",
    "        self.world.set_weather(weather)\n",
    "        \n",
    "    def destroy(self):\n",
    "        for actor in self.actorlist:\n",
    "            actor.destroy()\n",
    "        print(\"All Cleared\")\n",
    "\n",
    "\n",
    "def train_ppo_maml(env, state_dim, action_dim, lr=1e-4, n_iters=1000000, inner_loop_steps=5):\n",
    "    \n",
    " \n",
    "    p_low = 0\n",
    "    p_mid = 50\n",
    "    p_high = 100\n",
    "\n",
    "    pd_low = 50\n",
    "    pd_high = 100\n",
    "\n",
    "    tf_low = 0.5\n",
    "    tf_mid = 1.5\n",
    "    tf_high = 2.5\n",
    "    \n",
    "    conditions = [[p_low, pd_low, tf_high],\n",
    "            [p_low, pd_low, tf_mid],\n",
    "            [p_low, pd_high, tf_low],\n",
    "            [p_mid, pd_low, tf_low],\n",
    "            [p_mid, pd_high, tf_low],\n",
    "            [p_mid, pd_low, tf_mid],\n",
    "            [p_high, pd_low, tf_high],\n",
    "            [p_high, pd_high, tf_low],\n",
    "            [p_low, pd_high, tf_mid],\n",
    "            [p_high, pd_low, tf_mid]]\n",
    "    \n",
    "    n_tasks = len(conditions)\n",
    "\n",
    "    \n",
    "    base_model = NeuralNetwork(state_dim, action_dim)\n",
    "    maml = l2l.algorithms.MAML(base_model, lr = lr)\n",
    "    optimizer = optim.Adam(maml.parameters(), lr = lr)\n",
    "    iteration = 1\n",
    "    for condition in conditions:\n",
    "        \n",
    "        precipitation = condition[0]\n",
    "        precipitation_deposits = condition[1]\n",
    "        tire_friction = condition[2]\n",
    "        weather = carla.WeatherParameters( precipitation = precipitation,\n",
    "                                            precipitation_deposits = precipitation_deposits)\n",
    "        world.set_weather(weather)\n",
    "\n",
    "        tire_condition = carla.WheelPhysicsControl(tire_friction = tire_friction)\n",
    "\n",
    "        front_left_wheel  = carla.WheelPhysicsControl(tire_friction = tire_friction)\n",
    "        front_right_wheel = carla.WheelPhysicsControl(tire_friction = tire_friction)\n",
    "        rear_left_wheel   = carla.WheelPhysicsControl(tire_friction = tire_friction)\n",
    "        rear_right_wheel  = carla.WheelPhysicsControl(tire_friction = tire_friction)\n",
    "\n",
    "        wheels = [front_left_wheel, front_right_wheel, rear_left_wheel, rear_right_wheel]\n",
    "        \n",
    "        physics_control = env.vehicle.get_physics_control()\n",
    "        physics_control.wheels = wheels\n",
    "        env.vehicle.apply_physics_control(physics_control)\n",
    "    \n",
    "        trajectories, state_tensors, action_tensors = sample_trajectories(env, maml)\n",
    "        state_tensors_stacked = torch.stack(state_tensors)\n",
    "        action_tensors_stacked = torch.stack(action_tensors)\n",
    "        \n",
    "        for _ in range(inner_loop_steps):\n",
    "        \n",
    "            learner = maml.clone()\n",
    "            error = nn.MSELoss()(learner(state_tensors_stacked), action_tensors_stacked)\n",
    "            learner.adapt(error)\n",
    "            error = nn.MSELoss()(learner(state_tensors_stacked), action_tensors_stacked)\n",
    "            error.backward(retain_graph=True)\n",
    "\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        optimizer.step()\n",
    "        iteration += 1\n",
    "        print(\"Iteration for {condition}: \", iteration)\n",
    "\n",
    "        if iteration % 1000 == 0:\n",
    "            print(\"Iteration for {condition}: \", iteration)\n",
    "\n",
    "\n",
    "def sample_weather_conditions(num_weather_conditions):\n",
    "    return carla.WeatherParameters.HardRainNoon\n",
    "\n",
    "def sample_trajectories(env, model, num_episodes=10, max_episode_length=1000):\n",
    "#     model.to(\"cpu\")\n",
    "    trajectories = []\n",
    "    traj_states = []\n",
    "    traj_action = []\n",
    "    state_tensors = []\n",
    "    action_tensors = []\n",
    "       \n",
    "    for _ in range(num_episodes):\n",
    "        state = env.reset()                \n",
    "        trajectory = []\n",
    "\n",
    "        for j in range(max_episode_length):\n",
    "            \n",
    "#             state_tensor = torch.tensor(state).to(torch.float32)\n",
    "            state_tensor = torch.from_numpy(state.astype(np.float32))\n",
    "            state_tensors.append(state_tensor)\n",
    "            action_tensor = model(state_tensor)\n",
    "#             action_distribution = Normal(action_mean, torch.tensor(0.1))\n",
    "#             action = action_distribution.sample().detach().numpy().astype(float)\n",
    "            \n",
    "            action = action_tensor\n",
    "#             action_tensor = torch.tensor(action, dtype=torch.float32)\n",
    "            action_tensors.append(action)\n",
    "\n",
    "            next_state, reward, done = env.step(action)\n",
    "            trajectory.append((state, action, reward, next_state, done))\n",
    "\n",
    "            state = next_state\n",
    "            \n",
    "            if not j%200 : print(\"Reward: \", reward, '  J: ', j )\n",
    "            #state_tensors = torch.tensor(state_tensor, dtype=torch.float32)\n",
    "            if done or j==max_episode_length-1:\n",
    "                #env.vehicle.destroy()\n",
    "                break  \n",
    "\n",
    "        trajectories.append(trajectory)\n",
    "    return trajectories, state_tensors, action_tensors\n",
    "\n",
    "            \n",
    "def read_waypoints(file_path):\n",
    "    waypoints = []\n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        for row in csvreader:\n",
    "            v, yaw_c, yaw_n, r, x, y = map(float, row)\n",
    "            waypoints.append((v, yaw_c, yaw_n, r, x, y))\n",
    "            \n",
    "    return waypoints                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24bed8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Version mismatch detected: You are trying to connect to a simulator that might be incompatible with this API \n",
      "WARNING: Client API version     = 0.9.14 \n",
      "WARNING: Simulator API version  = 0.9.14-4-gf14acb257 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7909103631973267   J:  200\n",
      "Reward:  1.720502495765686   J:  400\n",
      "Reward:  1.553402841091156   J:  600\n",
      "Reward:  1.418022871017456   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7444543838500977   J:  200\n",
      "Reward:  1.6693082451820374   J:  400\n",
      "Reward:  1.6296700835227966   J:  600\n",
      "Reward:  1.5182350873947144   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7769770622253418   J:  200\n",
      "Reward:  1.7193748950958252   J:  400\n",
      "Reward:  1.6257873177528381   J:  600\n",
      "Reward:  1.5058684349060059   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7515251636505127   J:  200\n",
      "Reward:  1.6619996428489685   J:  400\n",
      "Reward:  1.5368287563323975   J:  600\n",
      "Reward:  1.4083020687103271   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7510809898376465   J:  200\n",
      "Reward:  1.6862658858299255   J:  400\n",
      "Reward:  1.5930089950561523   J:  600\n",
      "Reward:  1.463488757610321   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.775291085243225   J:  200\n",
      "Reward:  1.7235506772994995   J:  400\n",
      "Reward:  1.6362677812576294   J:  600\n",
      "Reward:  1.5886939764022827   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7735371589660645   J:  200\n",
      "Reward:  1.724574089050293   J:  400\n",
      "Reward:  1.6356921195983887   J:  600\n",
      "Reward:  1.6356921195983887   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7694318294525146   J:  200\n",
      "Reward:  1.6927334070205688   J:  400\n",
      "Reward:  1.6927334070205688   J:  600\n",
      "Reward:  1.576176106929779   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7641085386276245   J:  200\n",
      "Reward:  1.6813483834266663   J:  400\n",
      "Reward:  1.5676798224449158   J:  600\n",
      "Reward:  1.5676798224449158   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7575839757919312   J:  200\n",
      "Reward:  1.6743491291999817   J:  400\n",
      "Reward:  1.5466603636741638   J:  600\n",
      "Reward:  1.5466603636741638   J:  800\n",
      "Iteration for {condition}:  2\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7442660331726074   J:  200\n",
      "Reward:  1.683779239654541   J:  400\n",
      "Reward:  1.6090141534805298   J:  600\n",
      "Reward:  1.5317335724830627   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7908235788345337   J:  200\n",
      "Reward:  1.7908235788345337   J:  400\n",
      "Reward:  1.7908235788345337   J:  600\n",
      "Reward:  1.6924623250961304   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7687122821807861   J:  200\n",
      "Reward:  1.6908085942268372   J:  400\n",
      "Reward:  1.6055190563201904   J:  600\n",
      "Reward:  1.4893523454666138   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7636862993240356   J:  200\n",
      "Reward:  1.7069025039672852   J:  400\n",
      "Reward:  1.6523614525794983   J:  600\n",
      "Reward:  1.5080513954162598   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7539516687393188   J:  200\n",
      "Reward:  1.7095075845718384   J:  400\n",
      "Reward:  1.654670238494873   J:  600\n",
      "Reward:  1.498991072177887   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7538237571716309   J:  200\n",
      "Reward:  1.7095082998275757   J:  400\n",
      "Reward:  1.650860071182251   J:  600\n",
      "Reward:  1.5271841287612915   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.768531084060669   J:  200\n",
      "Reward:  1.69389009475708   J:  400\n",
      "Reward:  1.570309817790985   J:  600\n",
      "Reward:  1.4571157693862915   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7613213062286377   J:  200\n",
      "Reward:  1.701110064983368   J:  400\n",
      "Reward:  1.6579943299293518   J:  600\n",
      "Reward:  1.5496207475662231   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7660645246505737   J:  200\n",
      "Reward:  1.7396223545074463   J:  400\n",
      "Reward:  1.65012788772583   J:  600\n",
      "Reward:  1.5215545892715454   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7648251056671143   J:  200\n",
      "Reward:  1.7009829878807068   J:  400\n",
      "Reward:  1.6539241075515747   J:  600\n",
      "Reward:  1.600335717201233   J:  800\n",
      "Iteration for {condition}:  3\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7640410661697388   J:  200\n",
      "Reward:  1.7423954010009766   J:  400\n",
      "Reward:  1.6769177317619324   J:  600\n",
      "Reward:  1.5858153700828552   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7777013778686523   J:  200\n",
      "Reward:  1.7294858694076538   J:  400\n",
      "Reward:  1.6536452770233154   J:  600\n",
      "Reward:  1.547266662120819   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.772618293762207   J:  200\n",
      "Reward:  1.725083827972412   J:  400\n",
      "Reward:  1.6871528029441833   J:  600\n",
      "Reward:  1.5904696583747864   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7749062776565552   J:  200\n",
      "Reward:  1.7255914211273193   J:  400\n",
      "Reward:  1.6887320280075073   J:  600\n",
      "Reward:  1.593026578426361   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7502822875976562   J:  200\n",
      "Reward:  1.7223291397094727   J:  400\n",
      "Reward:  1.6453996300697327   J:  600\n",
      "Reward:  1.5928871631622314   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7739652395248413   J:  200\n",
      "Reward:  1.7246977090835571   J:  400\n",
      "Reward:  1.6877403855323792   J:  600\n",
      "Reward:  1.5821779370307922   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7736456394195557   J:  200\n",
      "Reward:  1.7178304195404053   J:  400\n",
      "Reward:  1.6714136004447937   J:  600\n",
      "Reward:  1.5494627952575684   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.755804181098938   J:  200\n",
      "Reward:  1.7145253419876099   J:  400\n",
      "Reward:  1.6591296792030334   J:  600\n",
      "Reward:  1.5833380818367004   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.763110876083374   J:  200\n",
      "Reward:  1.7286970615386963   J:  400\n",
      "Reward:  1.6836099028587341   J:  600\n",
      "Reward:  1.6267839074134827   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7451032400131226   J:  200\n",
      "Reward:  1.6148478984832764   J:  400\n",
      "Reward:  1.5304571986198425   J:  600\n",
      "Reward:  1.4636870622634888   J:  800\n",
      "Iteration for {condition}:  4\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7742314338684082   J:  200\n",
      "Reward:  1.7167975902557373   J:  400\n",
      "Reward:  1.672784149646759   J:  600\n",
      "Reward:  1.5570743083953857   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7731209993362427   J:  200\n",
      "Reward:  1.7144187688827515   J:  400\n",
      "Reward:  1.6683934926986694   J:  600\n",
      "Reward:  1.556441843509674   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7652429342269897   J:  200\n",
      "Reward:  1.7124918699264526   J:  400\n",
      "Reward:  1.6615227460861206   J:  600\n",
      "Reward:  1.6113903522491455   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7724756002426147   J:  200\n",
      "Reward:  1.7144248485565186   J:  400\n",
      "Reward:  1.6112784147262573   J:  600\n",
      "Reward:  1.5483508706092834   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.773960828781128   J:  200\n",
      "Reward:  1.7470701932907104   J:  400\n",
      "Reward:  1.6680216789245605   J:  600\n",
      "Reward:  1.6185159087181091   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.772497534751892   J:  200\n",
      "Reward:  1.7105927467346191   J:  400\n",
      "Reward:  1.6667455434799194   J:  600\n",
      "Reward:  1.5565428733825684   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7677626609802246   J:  200\n",
      "Reward:  1.7047749757766724   J:  400\n",
      "Reward:  1.655689299106598   J:  600\n",
      "Reward:  1.543361783027649   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7714271545410156   J:  200\n",
      "Reward:  1.7097806930541992   J:  400\n",
      "Reward:  1.6704899668693542   J:  600\n",
      "Reward:  1.5531525015830994   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7701447010040283   J:  200\n",
      "Reward:  1.741219162940979   J:  400\n",
      "Reward:  1.6598471403121948   J:  600\n",
      "Reward:  1.603781819343567   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7659902572631836   J:  200\n",
      "Reward:  1.7097386121749878   J:  400\n",
      "Reward:  1.666891634464264   J:  600\n",
      "Reward:  1.5512096881866455   J:  800\n",
      "Iteration for {condition}:  5\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.771196961402893   J:  200\n",
      "Reward:  1.7466025352478027   J:  400\n",
      "Reward:  1.6622360348701477   J:  600\n",
      "Reward:  1.5472089052200317   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7667793035507202   J:  200\n",
      "Reward:  1.7412188053131104   J:  400\n",
      "Reward:  1.6563268899917603   J:  600\n",
      "Reward:  1.6050077080726624   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7699570655822754   J:  200\n",
      "Reward:  1.7444484233856201   J:  400\n",
      "Reward:  1.6674635410308838   J:  600\n",
      "Reward:  1.554615080356598   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7685400247573853   J:  200\n",
      "Reward:  1.7051012516021729   J:  400\n",
      "Reward:  1.6608309149742126   J:  600\n",
      "Reward:  1.5479824542999268   J:  800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7731844186782837   J:  200\n",
      "Reward:  1.7469037771224976   J:  400\n",
      "Reward:  1.6676188111305237   J:  600\n",
      "Reward:  1.4733890891075134   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7710598707199097   J:  200\n",
      "Reward:  1.7126985788345337   J:  400\n",
      "Reward:  1.6644995212554932   J:  600\n",
      "Reward:  1.6079776287078857   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.768855094909668   J:  200\n",
      "Reward:  1.7079108953475952   J:  400\n",
      "Reward:  1.6590557098388672   J:  600\n",
      "Reward:  1.5390364527702332   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7735605239868164   J:  200\n",
      "Reward:  1.7145267724990845   J:  400\n",
      "Reward:  1.6721057891845703   J:  600\n",
      "Reward:  1.6179659962654114   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.768631100654602   J:  200\n",
      "Reward:  1.7428185939788818   J:  400\n",
      "Reward:  1.7048790454864502   J:  600\n",
      "Reward:  1.598329246044159   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7734768390655518   J:  200\n",
      "Reward:  1.7507948875427246   J:  400\n",
      "Reward:  1.6741358637809753   J:  600\n",
      "Reward:  1.5608391761779785   J:  800\n",
      "Iteration for {condition}:  6\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.77310311794281   J:  200\n",
      "Reward:  1.7472329139709473   J:  400\n",
      "Reward:  1.6635128855705261   J:  600\n",
      "Reward:  1.6158390045166016   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.769912600517273   J:  200\n",
      "Reward:  1.7092450857162476   J:  400\n",
      "Reward:  1.6588253378868103   J:  600\n",
      "Reward:  1.6102076172828674   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.771846055984497   J:  200\n",
      "Reward:  1.7081817388534546   J:  400\n",
      "Reward:  1.6630755066871643   J:  600\n",
      "Reward:  1.6075788736343384   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7726809978485107   J:  200\n",
      "Reward:  1.748651146888733   J:  400\n",
      "Reward:  1.6645561456680298   J:  600\n",
      "Reward:  1.6164957284927368   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7715755701065063   J:  200\n",
      "Reward:  1.7109284400939941   J:  400\n",
      "Reward:  1.664639413356781   J:  600\n",
      "Reward:  1.6115140914916992   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.771835446357727   J:  200\n",
      "Reward:  1.745195746421814   J:  400\n",
      "Reward:  1.6632437109947205   J:  600\n",
      "Reward:  1.6032498478889465   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.771624207496643   J:  200\n",
      "Reward:  1.7455745935440063   J:  400\n",
      "Reward:  1.6635649800300598   J:  600\n",
      "Reward:  1.610608696937561   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7169671058654785   J:  200\n",
      "Reward:  1.6761876344680786   J:  400\n",
      "Reward:  1.5708950757980347   J:  600\n",
      "Reward:  1.5006135702133179   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7716363668441772   J:  200\n",
      "Reward:  1.7434093952178955   J:  400\n",
      "Reward:  1.7072851657867432   J:  600\n",
      "Reward:  1.6079063415527344   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.772182583808899   J:  200\n",
      "Reward:  1.714367151260376   J:  400\n",
      "Reward:  1.6705044507980347   J:  600\n",
      "Reward:  1.6147301197052002   J:  800\n",
      "Iteration for {condition}:  7\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7700397968292236   J:  200\n",
      "Reward:  1.738437294960022   J:  400\n",
      "Reward:  1.6969637274742126   J:  600\n",
      "Reward:  1.5804886221885681   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.769046664237976   J:  200\n",
      "Reward:  1.738806962966919   J:  400\n",
      "Reward:  1.6928932666778564   J:  600\n",
      "Reward:  1.5562790632247925   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7875090837478638   J:  200\n",
      "Reward:  1.7231338024139404   J:  400\n",
      "Reward:  1.6662038564682007   J:  600\n",
      "Reward:  1.5943492650985718   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7516893148422241   J:  200\n",
      "Reward:  1.7065473794937134   J:  400\n",
      "Reward:  1.6392363905906677   J:  600\n",
      "Reward:  1.5466259121894836   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7497916221618652   J:  200\n",
      "Reward:  1.7019518613815308   J:  400\n",
      "Reward:  1.7019518613815308   J:  600\n",
      "Reward:  1.6230298280715942   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7592509984970093   J:  200\n",
      "Reward:  1.716010332107544   J:  400\n",
      "Reward:  1.6548014283180237   J:  600\n",
      "Reward:  1.578073799610138   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7296804189682007   J:  200\n",
      "Reward:  1.7296804189682007   J:  400\n",
      "Reward:  1.7296804189682007   J:  600\n",
      "Reward:  1.5811133980751038   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7451032400131226   J:  200\n",
      "Reward:  1.7451032400131226   J:  400\n",
      "Reward:  1.6092488765716553   J:  600\n",
      "Reward:  1.6092488765716553   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7594090700149536   J:  200\n",
      "Reward:  1.7136074304580688   J:  400\n",
      "Reward:  1.6524014472961426   J:  600\n",
      "Reward:  1.573037028312683   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.756106972694397   J:  200\n",
      "Reward:  1.7111347913742065   J:  400\n",
      "Reward:  1.6494677662849426   J:  600\n",
      "Reward:  1.5722020864486694   J:  800\n",
      "Iteration for {condition}:  8\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.785378098487854   J:  200\n",
      "Reward:  1.7119659185409546   J:  400\n",
      "Reward:  1.7119659185409546   J:  600\n",
      "Reward:  1.6340457797050476   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7513370513916016   J:  200\n",
      "Reward:  1.7109304666519165   J:  400\n",
      "Reward:  1.6440920233726501   J:  600\n",
      "Reward:  1.560315489768982   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7587075233459473   J:  200\n",
      "Reward:  1.7122678756713867   J:  400\n",
      "Reward:  1.6526594758033752   J:  600\n",
      "Reward:  1.5799623131752014   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.752640724182129   J:  200\n",
      "Reward:  1.7038992643356323   J:  400\n",
      "Reward:  1.6428491473197937   J:  600\n",
      "Reward:  1.5618686079978943   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7555843591690063   J:  200\n",
      "Reward:  1.7092353105545044   J:  400\n",
      "Reward:  1.6476039290428162   J:  600\n",
      "Reward:  1.5521111488342285   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.756883978843689   J:  200\n",
      "Reward:  1.756883978843689   J:  400\n",
      "Reward:  1.6443932056427002   J:  600\n",
      "Reward:  1.5731360912322998   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7835713624954224   J:  200\n",
      "Reward:  1.7497456073760986   J:  400\n",
      "Reward:  1.6426857113838196   J:  600\n",
      "Reward:  1.5698499083518982   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7520692348480225   J:  200\n",
      "Reward:  1.7520692348480225   J:  400\n",
      "Reward:  1.634641408920288   J:  600\n",
      "Reward:  1.4567086100578308   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.754785418510437   J:  200\n",
      "Reward:  1.7058535814285278   J:  400\n",
      "Reward:  1.6445989608764648   J:  600\n",
      "Reward:  1.5614827871322632   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.754272222518921   J:  200\n",
      "Reward:  1.7091877460479736   J:  400\n",
      "Reward:  1.6442900896072388   J:  600\n",
      "Reward:  1.5634757280349731   J:  800\n",
      "Iteration for {condition}:  9\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7842680215835571   J:  200\n",
      "Reward:  1.7032859325408936   J:  400\n",
      "Reward:  1.6342575550079346   J:  600\n",
      "Reward:  1.5635380148887634   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7553377151489258   J:  200\n",
      "Reward:  1.7066413164138794   J:  400\n",
      "Reward:  1.6409761905670166   J:  600\n",
      "Reward:  1.5513567924499512   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7529436349868774   J:  200\n",
      "Reward:  1.7055376768112183   J:  400\n",
      "Reward:  1.6435836553573608   J:  600\n",
      "Reward:  1.5512471795082092   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7607194185256958   J:  200\n",
      "Reward:  1.7163666486740112   J:  400\n",
      "Reward:  1.7163666486740112   J:  600\n",
      "Reward:  1.5699472427368164   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7560099363327026   J:  200\n",
      "Reward:  1.7560099363327026   J:  400\n",
      "Reward:  1.6408382654190063   J:  600\n",
      "Reward:  1.5593366026878357   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.757003903388977   J:  200\n",
      "Reward:  1.7123876810073853   J:  400\n",
      "Reward:  1.6518704891204834   J:  600\n",
      "Reward:  1.6518704891204834   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7571669816970825   J:  200\n",
      "Reward:  1.7096267938613892   J:  400\n",
      "Reward:  1.7096267938613892   J:  600\n",
      "Reward:  1.5686009526252747   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7565394639968872   J:  200\n",
      "Reward:  1.715378761291504   J:  400\n",
      "Reward:  1.652473270893097   J:  600\n",
      "Reward:  1.5684271454811096   J:  800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.753617763519287   J:  200\n",
      "Reward:  1.7078702449798584   J:  400\n",
      "Reward:  1.6525784134864807   J:  600\n",
      "Reward:  1.566231608390808   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7568917274475098   J:  200\n",
      "Reward:  1.708061933517456   J:  400\n",
      "Reward:  1.646802306175232   J:  600\n",
      "Reward:  1.5603755116462708   J:  800\n",
      "Iteration for {condition}:  10\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7759673595428467   J:  200\n",
      "Reward:  1.7247108221054077   J:  400\n",
      "Reward:  1.6744953393936157   J:  600\n",
      "Reward:  1.6060082912445068   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7767575979232788   J:  200\n",
      "Reward:  1.725818157196045   J:  400\n",
      "Reward:  1.676698625087738   J:  600\n",
      "Reward:  1.585311233997345   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.775455355644226   J:  200\n",
      "Reward:  1.726457953453064   J:  400\n",
      "Reward:  1.6788659691810608   J:  600\n",
      "Reward:  1.6084001660346985   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7643983364105225   J:  200\n",
      "Reward:  1.7098197937011719   J:  400\n",
      "Reward:  1.6558032035827637   J:  600\n",
      "Reward:  1.5648953318595886   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.765929102897644   J:  200\n",
      "Reward:  1.7124890089035034   J:  400\n",
      "Reward:  1.6552698016166687   J:  600\n",
      "Reward:  1.5627662539482117   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.765136480331421   J:  200\n",
      "Reward:  1.730883002281189   J:  400\n",
      "Reward:  1.6592437028884888   J:  600\n",
      "Reward:  1.5924490094184875   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7722644805908203   J:  200\n",
      "Reward:  1.7179161310195923   J:  400\n",
      "Reward:  1.6597766280174255   J:  600\n",
      "Reward:  1.5873903632164001   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7715529203414917   J:  200\n",
      "Reward:  1.7280961275100708   J:  400\n",
      "Reward:  1.6633623838424683   J:  600\n",
      "Reward:  1.6087098121643066   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7713910341262817   J:  200\n",
      "Reward:  1.7284938097000122   J:  400\n",
      "Reward:  1.6892906427383423   J:  600\n",
      "Reward:  1.6098061800003052   J:  800\n",
      "Reward:  139.78680419921875   J:  0\n",
      "Reward:  1.7644448280334473   J:  200\n",
      "Reward:  1.6970043778419495   J:  400\n",
      "Reward:  1.6052109003067017   J:  600\n",
      "Reward:  1.4777204394340515   J:  800\n",
      "Iteration for {condition}:  11\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    client = carla.Client('localhost', 2000)\n",
    "    client.set_timeout(2.0)\n",
    "\n",
    "    world = client.get_world()\n",
    "    blueprint_library = world.get_blueprint_library()\n",
    "    vehicle_blueprint = blueprint_library.filter(\"wrangler_rubicon\")[0]\n",
    "\n",
    "    waypoints = read_waypoints(\"waypoint_with_xy.csv\")\n",
    "    env = CarlaEnvironment(world, vehicle_blueprint, waypoints)  # Implement CarlaEnvironment with the required state and action spaces\n",
    "\n",
    "    state_dim = 40\n",
    "    action_dim = 3\n",
    "    train_ppo_maml(env, state_dim, action_dim)\n",
    "    \n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902c86f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
