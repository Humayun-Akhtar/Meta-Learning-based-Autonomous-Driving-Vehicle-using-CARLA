{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import gym as gym\n",
    "from gym import spaces\n",
    "import carla\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.sac.policies import MlpPolicy\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "import csv\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 2\n",
    "CSV_FILE = '/home/kololhe/stuff/waypoints.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_waypoints(file_path):\n",
    "    waypoints = []\n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        for row in csvreader:\n",
    "            x, y, yaw = map(float, row)\n",
    "            waypoints.append((x, y, yaw))\n",
    "            \n",
    "    return waypoints\n",
    "\n",
    "\n",
    "def setupCarla():\n",
    "\n",
    "    # Connect to CARLA server\n",
    "    client = carla.Client('localhost', 2000)\n",
    "    client.set_timeout(10.0)\n",
    "\n",
    "    return client.get_world()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarlaInstance(gym.Env):\n",
    "    metadata = {}\n",
    "\n",
    "    def __init__(self, world, waypoints):\n",
    "        #super(CarlaInstance, self).__init__()\n",
    "        try:\n",
    "            self.waypoints = waypoints\n",
    "            self.current_waypoint_index = 0\n",
    "\n",
    "            self.blueprint_library = world.get_blueprint_library()\n",
    "            world.set_weather(carla.WeatherParameters.ClearNoon)\n",
    "\n",
    "\n",
    "            # Spawn vehicle\n",
    "            vehicle_bp = random.choice(self.blueprint_library.filter('wrangler_rubicon'))\n",
    "            spawn_point = carla.Transform(carla.Location(x=-23.6,y=137.5,z=1),carla.Rotation(yaw=0))\n",
    "            self.vehicle = world.spawn_actor(vehicle_bp, spawn_point)\n",
    "            #self.vehicle.set_simulate_physics(True)\n",
    "            self.vehicle.apply_control(carla.VehicleControl(throttle=1.0, brake=0.0, steer=0.0))\n",
    "            sleep(2.0)\n",
    "\n",
    "            # Attach Lane Invasion Sensor to car\n",
    "            sensor_bp = world.get_blueprint_library().find('sensor.other.lane_invasion')\n",
    "            sensor_transform = carla.Transform(carla.Location(x=2.5, z=0.7))\n",
    "            self.lane_invasion_sensor = world.spawn_actor(sensor_bp, sensor_transform, attach_to=self.vehicle)\n",
    "            self.lane_invasion_sensor.listen(lambda event: self.on_lane_invasion(event))\n",
    "\n",
    "            self.collision_sensor = world.spawn_actor(world.get_blueprint_library().find('sensor.other.collision'), sensor_transform, attach_to=self.vehicle)\n",
    "            self.collision_sensor.listen(lambda event: self.on_lane_invasion(event))\n",
    "\n",
    "            self.action_space = spaces.Box(low = 0.0, high=1.0, shape=(1,), dtype=np.float32)\n",
    "            self.observation_space = spaces.Box(low=-500000, high=500000, shape=(5,), dtype=np.float64)\n",
    "            self.problem = bool\n",
    "            #self.reset()\n",
    "\n",
    "        except RuntimeError or KeyboardInterrupt:\n",
    "            print(\"entered init exception\")\n",
    "            for actor in world.get_actors():\n",
    "                actor.destroy()\n",
    "            pass\n",
    "\n",
    "    def on_lane_invasion(self, event):\n",
    "        self.problem = True \n",
    "        #print(\"Theek kar\")\n",
    "        self.reset()\n",
    "    \n",
    "    def step(self, action):\n",
    "\n",
    "        #print(\"{}\\n\", format(action))\n",
    "        \n",
    "        #throttle = action[0]\n",
    "        #steer = action[1]\n",
    "        #brake = 0\n",
    "        # print(action)\n",
    "        # if action.any() == None:\n",
    "        #     reward = -10000\n",
    "        \n",
    "        throttle = action[0].astype(np.float32)\n",
    "        steer = 0\n",
    "        brake = 0\n",
    "\n",
    "        control = carla.VehicleControl(throttle=throttle, brake=brake, steer=steer) #, steer=steer)\n",
    "        self.vehicle.apply_control(control)\n",
    "        \n",
    "        #Getting next waypoint\n",
    "        next_state = self.get_state()\n",
    "        \n",
    "        # Calculate reward\n",
    "        reward = self.calculate_reward(next_state)\n",
    "\n",
    "        # Check if the episode is done\n",
    "        done = self.is_done(next_state)\n",
    "\n",
    "        return next_state, reward, done\n",
    "        \n",
    "        #next_waypoint = self.waypoints[self.current_waypoint_index]\n",
    "        #next_waypoint_location = carla.Location(x=next_waypoint[0], y=next_waypoint[1])\n",
    "#         current_location = self.vehicle.get_location()\n",
    "#         distance = current_location.distance(next_waypoint_location)\n",
    "\n",
    "#         if distance < threshold:\n",
    "#             self.current_waypoint_index += 1\n",
    "#             if self.current_waypoint_index >= len(self.waypoints):\n",
    "#                 self.current_waypoint_index = 0\n",
    "\n",
    "#         reward = self.get_reward(distance, control)\n",
    "#         done = False\n",
    "#         if self.current_waypoint_index == len(self.waypoints) - 1 or self.problem:\n",
    "#             done = True\n",
    "# #         print (f'step taken: Throttle: {throttle} and steer: {steer}')\n",
    "#         info = {}\n",
    "#         sleep(0.05)\n",
    "\n",
    "        #return self.get_observation(), reward, done, info\n",
    "    \n",
    "    def get_state(self):\n",
    "        state = []\n",
    "        curr_yaw = self.vehicle.get_transform().rotation.yaw\n",
    "\n",
    "\n",
    "        for i in range(10):\n",
    "            if self.current_waypoint + i < len(self.waypoints):\n",
    "                waypoint = self.waypoints[self.current_waypoint + i]\n",
    "                curr_vel = self.vehicle.get_velocity()\n",
    "                curr_loc = self.vehicle.get_location()\n",
    "                vx = curr_vel.x\n",
    "                vy = curr_vel.y\n",
    "                v = ((vx)**2+(vy)**2)**0.5\n",
    "                distance = curr_loc.distance(carla.Location(x=waypoint[4],y=waypoint[5]))\n",
    "                state.extend([v, curr_yaw - waypoint[1], curr_yaw - waypoint[2], distance ])\n",
    "            else:\n",
    "                state.extend([0, 0, 0, 0])\n",
    "        return np.array(state)\n",
    "    \n",
    "    \n",
    "#     def get_observation(self):\n",
    "#         location = self.vehicle.get_location()\n",
    "#         orientation = self.vehicle.get_transform().rotation.yaw\n",
    "#         speed = self.vehicle.get_velocity()\n",
    "#         speed = np.sqrt(speed.x**2 + speed.y**2 + speed.z**2)\n",
    "#         next_waypoint = self.waypoints[self.current_waypoint_index]\n",
    "#         next_waypoint_location = carla.Location(x=next_waypoint[0], y=next_waypoint[1])\n",
    "#         distance = location.distance(next_waypoint_location)\n",
    "# #         print('observation taken')\n",
    "\n",
    "#         return np.array([location.x, location.y, orientation, speed, distance], dtype=np.float64)\n",
    "    \n",
    "#     def get_reward(self, distance, control):\n",
    "#         reward = 0\n",
    "#         if control.throttle > 0.9:\n",
    "#             reward += 5\n",
    "#         if distance < threshold:        \n",
    "#             reward += distance+100    \n",
    "#         if distance == 0:\n",
    "#             reward += 1000\n",
    "#         if self.vehicle.get_location() == carla.Transform(carla.Location(x=-23.6,y=137.5,z=1),carla.Rotation(yaw=0)):\n",
    "#             reward -=500\n",
    "\n",
    "#         # Apply a large negative reward for lane invasion\n",
    "# #         print('reward calculated')    \n",
    "#         return reward\n",
    "    def calculate_reward(self, state):\n",
    "        reward = -(np.linalg.norm(state[0] - self.waypoints[self.current_waypoint][0]) - (np.linalg.norm (state[1])) - (np.linalg.norm ( state[2])) - (np.linalg.norm (state[3])) + self.current_waypoint)\n",
    "        return reward\n",
    "\n",
    "    def is_done(self, state):\n",
    "        if self.e == 1:\n",
    "            self.current_waypoint += 1\n",
    "            self.e=2\n",
    "        if np.abs(state[3]) < 0.20:  # If the vehicle is close to the next waypoint\n",
    "            self.current_waypoint += 1\n",
    "\n",
    "        if self.current_waypoint >= len(self.waypoints):\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "    \n",
    "    def close(self):\n",
    "        self.vehicle.destroy()\n",
    "        self.lane_invasion_sensor.destroy()\n",
    "        self.collision_sensor.destroy()    \n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        vel = carla.Vector3D()\n",
    "        vel.x = 0\n",
    "        vel.y = 0\n",
    "        vel.z = 0\n",
    "        self.vehicle.set_target_velocity(vel)\n",
    "        x, y, yaw = self.waypoints[0]\n",
    "        transform = carla.Transform(carla.Location(x=-23.6,y=137.5),carla.Rotation(yaw=0))\n",
    "        self.vehicle.set_transform(transform)\n",
    "        self.current_waypoint_index = 0        \n",
    "\n",
    "        info = {}\n",
    "\n",
    "        return self.get_observation()\n",
    "    \n",
    "    def render(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vectorized environment with SubprocVecEnv\n",
    "num_envs=1\n",
    "env = CarlaInstance(world = setupCarla(), waypoints = read_waypoints(CSV_FILE))\n",
    "\n",
    "check_env(env)\n",
    "\n",
    "# Instantiate the PPO agent\n",
    "model = SAC(\"MlpPolicy\", env, verbose=1, gamma=0.99, learning_rate=0.0005, target_update_interval=1000, tau= 0.005)\n",
    "\n",
    "# Train the agent\n",
    "model.learn(total_timesteps=1000000, progress_bar=True, reset_num_timesteps=50000)\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"carla_ppo\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
